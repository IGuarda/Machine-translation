{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traductor Español-Inglés Machine translation\n",
    "### Ignacio Díaz-Guardamino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a text file of English-German sentence pairs. First we will read the file using the function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function to split the text into English-German pairs separated by '\\n' and then split these pairs into English sentences and German sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Download the data from [here.](http://www.manythings.org/anki/deu-eng.zip)__ and extract \"deu.txt\" in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"spa.txt\")\n",
    "es_eng = to_lines(data)\n",
    "es_eng = array(es_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual data contains over 150,000 sentence-pairs. However, we will use the first 50,000 sentence pairs only to reduce the training time of the model. You can change this number as per you system computation power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_eng = es_eng[:50000,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning\n",
    "\n",
    "Let's take a look at our data, then we will decide which pre-processing steps to adopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Ve.'],\n",
       "       ['Go.', 'Vete.'],\n",
       "       ['Go.', 'Vaya.'],\n",
       "       ...,\n",
       "       ['I am waiting for my driver.', 'Estoy esperando a mi chofer.'],\n",
       "       ['I appreciate all your help.', 'Aprecio toda tu ayuda.'],\n",
       "       ['I appreciate your interest.', 'Agradezco tu interés.']],\n",
       "      dtype='<U332')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get rid of the punctuation marks, and then convert the text to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "es_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in es_eng[:,0]]\n",
    "es_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)).replace('¿', '') for s in es_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Ve'],\n",
       "       ['Go', 'Vete'],\n",
       "       ['Go', 'Vaya'],\n",
       "       ...,\n",
       "       ['I am waiting for my driver', 'Estoy esperando a mi chofer'],\n",
       "       ['I appreciate all your help', 'Aprecio toda tu ayuda'],\n",
       "       ['I appreciate your interest', 'Agradezco tu interés']],\n",
       "      dtype='<U332')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(es_eng)):\n",
    "    es_eng[i,0] = es_eng[i,0].lower()\n",
    "    \n",
    "    es_eng[i,1] = es_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 've'],\n",
       "       ['go', 'vete'],\n",
       "       ['go', 'vaya'],\n",
       "       ...,\n",
       "       ['i am waiting for my driver', 'estoy esperando a mi chofer'],\n",
       "       ['i appreciate all your help', 'aprecio toda tu ayuda'],\n",
       "       ['i appreciate your interest', 'agradezco tu interés']],\n",
       "      dtype='<U332')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text to Sequence Conversion\n",
    "\n",
    "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "es_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in es_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in es_eng[:,1]:\n",
    "    es_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       eng  es\n",
      "0        1   1\n",
      "1        1   1\n",
      "2        1   1\n",
      "3        1   1\n",
      "4        1   1\n",
      "...    ...  ..\n",
      "49995    6   5\n",
      "49996    8   6\n",
      "49997    6   5\n",
      "49998    5   4\n",
      "49999    4   3\n",
      "\n",
      "[50000 rows x 2 columns]\n",
      "8\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'es':es_l})\n",
    "print(length_df)\n",
    "print(max(length_df.eng))\n",
    "print(max(length_df.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum length of the German sentences is 11 and that of the English phrases is 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6942\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(es_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Vocabulary Size: 13809\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "es_tokenizer = tokenization(es_eng[:, 1])\n",
    "es_vocab_size = len(es_tokenizer.word_index) + 1\n",
    "\n",
    "es_length = 8\n",
    "print('Spanish Vocabulary Size: %d' % es_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(es_tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    print(seq)\n",
    "    print(len(seq))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into train and test set for model training and evaluation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(es_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to encode the sentences. We will encode German sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   10 1516 ...    0    0    0]\n",
      " [4710    4    6 ...    0    0    0]\n",
      " [  14 4834    0 ...    0    0    0]\n",
      " ...\n",
      " [  41  189 1606 ...    0    0    0]\n",
      " [  21   12   15 ...    8 1148    0]\n",
      " [   2  233 1420 ...    0    0    0]]\n",
      "40000\n",
      "[[   3  182   10 ...    0    0    0]\n",
      " [   1 1094    6 ...    0    0    0]\n",
      " [  50  101    9 ...    0    0    0]\n",
      " ...\n",
      " [  44  444  432 ...    0    0    0]\n",
      " [  22    4  123 ...  213    0    0]\n",
      " [   1  202 2244 ...    0    0    0]]\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(es_tokenizer, es_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 8)\n",
      "(40000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  53   41   30 ...    0    0    0]\n",
      " [ 220    4    1 ...    0    0    0]\n",
      " [  72 8386    0 ...    0    0    0]\n",
      " ...\n",
      " [9350  115  934 ...    0    0    0]\n",
      " [ 536   56  574 ...    0    0    0]\n",
      " [   2   33 6577 ...    0    0    0]]\n",
      "10000\n",
      "[[  36   16   40 ...    0    0    0]\n",
      " [   1   37    3 ...    0    0    0]\n",
      " [   2   99 1339 ...    0    0    0]\n",
      " ...\n",
      " [  56 1781   29 ...    0    0    0]\n",
      " [  33    2  217 ...    0    0    0]\n",
      " [   1  867   42 ...    0    0    0]]\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(es_tokenizer, es_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 8)\n",
      "(10000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))    \n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about the RepeatVector :  https://campus.datacamp.com/courses/machine-translation-in-python/implementing-an-encoder-decoder-model-with-keras?ex=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using RMSprop optimizer in this model as it is usually a good choice for recurrent neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13809\n",
      "6942\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(es_vocab_size)\n",
    "print(eng_vocab_size)\n",
    "print(es_length)\n",
    "print(eng_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(es_vocab_size, eng_vocab_size, es_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we have used __'sparse_categorical_crossentropy'__ as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we are all set to start training our model. We will train it for 30 epochs and with a batch size of 512. You may change and play these hyperparameters. We will also be using __ModelCheckpoint()__ to save the best model with lowest validation loss. I personally prefer this method over early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 64000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "64000/64000 [==============================] - 460s 7ms/step - loss: 4.6371 - val_loss: 4.3218\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.32182, saving model to model.h2.5-5-20\n",
      "Epoch 2/50\n",
      "64000/64000 [==============================] - 477s 7ms/step - loss: 4.1416 - val_loss: 4.0307\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.32182 to 4.03071, saving model to model.h2.5-5-20\n",
      "Epoch 3/50\n",
      "64000/64000 [==============================] - 464s 7ms/step - loss: 3.9145 - val_loss: 3.8874\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.03071 to 3.88743, saving model to model.h2.5-5-20\n",
      "Epoch 4/50\n",
      "64000/64000 [==============================] - 467s 7ms/step - loss: 3.6800 - val_loss: 3.6338\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.88743 to 3.63378, saving model to model.h2.5-5-20\n",
      "Epoch 5/50\n",
      "64000/64000 [==============================] - 476s 7ms/step - loss: 3.4228 - val_loss: 3.4507\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.63378 to 3.45066, saving model to model.h2.5-5-20\n",
      "Epoch 6/50\n",
      "64000/64000 [==============================] - 479s 7ms/step - loss: 3.1910 - val_loss: 3.2292\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.45066 to 3.22923, saving model to model.h2.5-5-20\n",
      "Epoch 7/50\n",
      "64000/64000 [==============================] - 484s 8ms/step - loss: 2.9719 - val_loss: 3.0868\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.22923 to 3.08683, saving model to model.h2.5-5-20\n",
      "Epoch 8/50\n",
      "64000/64000 [==============================] - 476s 7ms/step - loss: 2.7671 - val_loss: 2.9153\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.08683 to 2.91529, saving model to model.h2.5-5-20\n",
      "Epoch 9/50\n",
      "64000/64000 [==============================] - 474s 7ms/step - loss: 2.5756 - val_loss: 2.7940\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.91529 to 2.79400, saving model to model.h2.5-5-20\n",
      "Epoch 10/50\n",
      "64000/64000 [==============================] - 472s 7ms/step - loss: 2.3954 - val_loss: 2.6749\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.79400 to 2.67491, saving model to model.h2.5-5-20\n",
      "Epoch 11/50\n",
      "64000/64000 [==============================] - 471s 7ms/step - loss: 2.2286 - val_loss: 2.5809\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.67491 to 2.58088, saving model to model.h2.5-5-20\n",
      "Epoch 12/50\n",
      "64000/64000 [==============================] - 468s 7ms/step - loss: 2.0764 - val_loss: 2.4946\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.58088 to 2.49462, saving model to model.h2.5-5-20\n",
      "Epoch 13/50\n",
      "64000/64000 [==============================] - 442s 7ms/step - loss: 1.9343 - val_loss: 2.4419\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.49462 to 2.44187, saving model to model.h2.5-5-20\n",
      "Epoch 14/50\n",
      "64000/64000 [==============================] - 462s 7ms/step - loss: 1.8049 - val_loss: 2.4002\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.44187 to 2.40020, saving model to model.h2.5-5-20\n",
      "Epoch 15/50\n",
      "64000/64000 [==============================] - 466s 7ms/step - loss: 1.6839 - val_loss: 2.3411\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.40020 to 2.34107, saving model to model.h2.5-5-20\n",
      "Epoch 16/50\n",
      "64000/64000 [==============================] - 467s 7ms/step - loss: 1.5709 - val_loss: 2.3324\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.34107 to 2.33236, saving model to model.h2.5-5-20\n",
      "Epoch 17/50\n",
      "64000/64000 [==============================] - 462s 7ms/step - loss: 1.4641 - val_loss: 2.2983\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.33236 to 2.29829, saving model to model.h2.5-5-20\n",
      "Epoch 18/50\n",
      "64000/64000 [==============================] - 466s 7ms/step - loss: 1.3652 - val_loss: 2.2768\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.29829 to 2.27677, saving model to model.h2.5-5-20\n",
      "Epoch 19/50\n",
      "64000/64000 [==============================] - 473s 7ms/step - loss: 1.2734 - val_loss: 2.2415\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.27677 to 2.24154, saving model to model.h2.5-5-20\n",
      "Epoch 20/50\n",
      "64000/64000 [==============================] - 463s 7ms/step - loss: 1.1861 - val_loss: 2.2173\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.24154 to 2.21733, saving model to model.h2.5-5-20\n",
      "Epoch 21/50\n",
      "64000/64000 [==============================] - 456s 7ms/step - loss: 1.1043 - val_loss: 2.2164\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.21733 to 2.21640, saving model to model.h2.5-5-20\n",
      "Epoch 22/50\n",
      "64000/64000 [==============================] - 451s 7ms/step - loss: 1.0260 - val_loss: 2.2063\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.21640 to 2.20627, saving model to model.h2.5-5-20\n",
      "Epoch 23/50\n",
      "64000/64000 [==============================] - 449s 7ms/step - loss: 0.9515 - val_loss: 2.2445\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.20627\n",
      "Epoch 24/50\n",
      "64000/64000 [==============================] - 453s 7ms/step - loss: 0.8855 - val_loss: 2.2197\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.20627\n",
      "Epoch 25/50\n",
      "64000/64000 [==============================] - 433s 7ms/step - loss: 0.8182 - val_loss: 2.2464\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.20627\n",
      "Epoch 26/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.7555 - val_loss: 2.2424\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.20627\n",
      "Epoch 27/50\n",
      "64000/64000 [==============================] - 432s 7ms/step - loss: 0.6986 - val_loss: 2.2599\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.20627\n",
      "Epoch 28/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.6427 - val_loss: 2.2766\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.20627\n",
      "Epoch 29/50\n",
      "64000/64000 [==============================] - 432s 7ms/step - loss: 0.5910 - val_loss: 2.3185\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.20627\n",
      "Epoch 30/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.5419 - val_loss: 2.3130\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.20627\n",
      "Epoch 31/50\n",
      "64000/64000 [==============================] - 432s 7ms/step - loss: 0.4957 - val_loss: 2.3762\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.20627\n",
      "Epoch 32/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.4546 - val_loss: 2.3610\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.20627\n",
      "Epoch 33/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.4149 - val_loss: 2.4210\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.20627\n",
      "Epoch 34/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.3794 - val_loss: 2.4250\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.20627\n",
      "Epoch 35/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.3455 - val_loss: 2.4404\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.20627\n",
      "Epoch 36/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.3158 - val_loss: 2.4717\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.20627\n",
      "Epoch 37/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.2876 - val_loss: 2.5175\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.20627\n",
      "Epoch 38/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.2620 - val_loss: 2.5304\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.20627\n",
      "Epoch 39/50\n",
      "64000/64000 [==============================] - 431s 7ms/step - loss: 0.2403 - val_loss: 2.5518\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.20627\n",
      "Epoch 40/50\n",
      "64000/64000 [==============================] - 428s 7ms/step - loss: 0.2192 - val_loss: 2.5678\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.20627\n",
      "Epoch 41/50\n",
      "64000/64000 [==============================] - 423s 7ms/step - loss: 0.2003 - val_loss: 2.6083\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.20627\n",
      "Epoch 42/50\n",
      "64000/64000 [==============================] - 424s 7ms/step - loss: 0.1842 - val_loss: 2.6429\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.20627\n",
      "Epoch 43/50\n",
      "64000/64000 [==============================] - 423s 7ms/step - loss: 0.1703 - val_loss: 2.6411\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.20627\n",
      "Epoch 44/50\n",
      "64000/64000 [==============================] - 424s 7ms/step - loss: 0.1575 - val_loss: 2.6751\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.20627\n",
      "Epoch 45/50\n",
      "64000/64000 [==============================] - 423s 7ms/step - loss: 0.1460 - val_loss: 2.7499\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.20627\n",
      "Epoch 46/50\n",
      "64000/64000 [==============================] - 424s 7ms/step - loss: 0.1367 - val_loss: 2.7202\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.20627\n",
      "Epoch 47/50\n",
      "64000/64000 [==============================] - 424s 7ms/step - loss: 0.1275 - val_loss: 2.7654\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.20627\n",
      "Epoch 48/50\n",
      "64000/64000 [==============================] - 424s 7ms/step - loss: 0.1197 - val_loss: 2.7637\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.20627\n",
      "Epoch 49/50\n",
      "64000/64000 [==============================] - 423s 7ms/step - loss: 0.1132 - val_loss: 2.7781\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.20627\n",
      "Epoch 50/50\n",
      "64000/64000 [==============================] - 424s 7ms/step - loss: 0.1071 - val_loss: 2.8036\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.20627\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h2.5-5-20'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=50, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)\n",
    "#modelo h1:  0.5847 - val_loss: 1.7952\n",
    "#modelo h2:  loss: 0.1071 - val_loss: 2.8036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the training loss and the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the saved model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h1.4-5-20')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'ES' : test[:,1], 'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ellos son muy optimistas</td>\n",
       "      <td>they are very cheerful</td>\n",
       "      <td>please about for you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conozco a tom</td>\n",
       "      <td>i know tom</td>\n",
       "      <td>help  tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>puedes negarte</td>\n",
       "      <td>you may refuse</td>\n",
       "      <td>just look a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eso es privado</td>\n",
       "      <td>thats private</td>\n",
       "      <td>its is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tom saltó desde su asiento</td>\n",
       "      <td>tom leaped from his seat</td>\n",
       "      <td>tom should me to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jamás has vendido un auto</td>\n",
       "      <td>have you ever sold a car</td>\n",
       "      <td>ten old will as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cuántos hijos tienes</td>\n",
       "      <td>how many kids do you have</td>\n",
       "      <td>well to   you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no te dejaré hacerlo</td>\n",
       "      <td>i will not let you do it</td>\n",
       "      <td>dont  it again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no es hermoso</td>\n",
       "      <td>isnt it beautiful</td>\n",
       "      <td>its not natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mi loro murió ayer</td>\n",
       "      <td>my parrot died yesterday</td>\n",
       "      <td>they gave to a to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>comí una manzana</td>\n",
       "      <td>i ate an apple</td>\n",
       "      <td>hold your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tom está contento</td>\n",
       "      <td>toms glad</td>\n",
       "      <td>tom is a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cubre mi espalda</td>\n",
       "      <td>watch my back</td>\n",
       "      <td>get us with me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tom está escondido</td>\n",
       "      <td>tom is hiding</td>\n",
       "      <td>tom is a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>póngalo allí</td>\n",
       "      <td>put it over there</td>\n",
       "      <td>please it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ES                     actual  \\\n",
       "0     ellos son muy optimistas     they are very cheerful   \n",
       "1                conozco a tom                 i know tom   \n",
       "2               puedes negarte             you may refuse   \n",
       "3               eso es privado              thats private   \n",
       "4   tom saltó desde su asiento   tom leaped from his seat   \n",
       "5    jamás has vendido un auto   have you ever sold a car   \n",
       "6         cuántos hijos tienes  how many kids do you have   \n",
       "7         no te dejaré hacerlo   i will not let you do it   \n",
       "8                no es hermoso          isnt it beautiful   \n",
       "9           mi loro murió ayer   my parrot died yesterday   \n",
       "10            comí una manzana             i ate an apple   \n",
       "11           tom está contento                  toms glad   \n",
       "12            cubre mi espalda              watch my back   \n",
       "13          tom está escondido              tom is hiding   \n",
       "14                póngalo allí          put it over there   \n",
       "\n",
       "                   predicted  \n",
       "0   please about for you      \n",
       "1             help  tom       \n",
       "2           just look a       \n",
       "3               its is        \n",
       "4    tom should me to you     \n",
       "5        ten old will as      \n",
       "6           well to   you     \n",
       "7         dont  it again      \n",
       "8       its not natural       \n",
       "9       they gave to a to     \n",
       "10           hold your        \n",
       "11             tom is a       \n",
       "12        get us with me      \n",
       "13             tom is a       \n",
       "14           please it        "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>tom y mary saben</td>\n",
       "      <td>do tom and mary know</td>\n",
       "      <td>where i be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>tom puede ser burdo</td>\n",
       "      <td>tom can be clumsy</td>\n",
       "      <td>tom thinks lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>querés probarlo</td>\n",
       "      <td>do you want to try it</td>\n",
       "      <td>i hate my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>sabes quién era</td>\n",
       "      <td>do you know who he was</td>\n",
       "      <td>tom was at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>también es una belleza</td>\n",
       "      <td>shes also a beauty</td>\n",
       "      <td>your is  dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>quiero a su hija</td>\n",
       "      <td>i love your daughter</td>\n",
       "      <td>i want something change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>él da clases de inglés</td>\n",
       "      <td>he teaches english</td>\n",
       "      <td>she is having for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>me quedé dormido</td>\n",
       "      <td>i overslept</td>\n",
       "      <td>he gave me a job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>él es pobre como pocos</td>\n",
       "      <td>he is as poor as can be</td>\n",
       "      <td>he is the  tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>dónde está mi camisa</td>\n",
       "      <td>wheres my shirt</td>\n",
       "      <td>this is tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>todo está bien aquí</td>\n",
       "      <td>is everything ok here</td>\n",
       "      <td>were are rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>me cansé de jugar esto</td>\n",
       "      <td>im sick of this game</td>\n",
       "      <td>i love you very well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>deshágase del arma</td>\n",
       "      <td>get rid of the gun</td>\n",
       "      <td>im on key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>viste esta película</td>\n",
       "      <td>did you watch this movie</td>\n",
       "      <td>i done did i do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>no tengo malicia hacia él</td>\n",
       "      <td>i bear him no malice</td>\n",
       "      <td>tom is a very tall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ES                    actual  \\\n",
       "9985           tom y mary saben      do tom and mary know   \n",
       "9986        tom puede ser burdo         tom can be clumsy   \n",
       "9987            querés probarlo     do you want to try it   \n",
       "9988            sabes quién era    do you know who he was   \n",
       "9989     también es una belleza        shes also a beauty   \n",
       "9990           quiero a su hija      i love your daughter   \n",
       "9991     él da clases de inglés        he teaches english   \n",
       "9992           me quedé dormido               i overslept   \n",
       "9993     él es pobre como pocos   he is as poor as can be   \n",
       "9994       dónde está mi camisa           wheres my shirt   \n",
       "9995        todo está bien aquí     is everything ok here   \n",
       "9996     me cansé de jugar esto      im sick of this game   \n",
       "9997         deshágase del arma        get rid of the gun   \n",
       "9998        viste esta película  did you watch this movie   \n",
       "9999  no tengo malicia hacia él      i bear him no malice   \n",
       "\n",
       "                        predicted  \n",
       "9985              where i be       \n",
       "9986        tom thinks lying       \n",
       "9987               i hate my       \n",
       "9988              tom was at       \n",
       "9989           your is  dirty      \n",
       "9990  i want something change      \n",
       "9991        she is having for      \n",
       "9992          he gave me a job     \n",
       "9993             he is the  tv     \n",
       "9994         this is tonight       \n",
       "9995           were are rich       \n",
       "9996      i love you very well     \n",
       "9997               im on key       \n",
       "9998           i done did i do     \n",
       "9999        tom is a very tall     "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>no soy la hermana de tom</td>\n",
       "      <td>im not toms sister</td>\n",
       "      <td>im not your tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>no debes salir hoy</td>\n",
       "      <td>you must not go out today</td>\n",
       "      <td>dont take your choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>eres realmente hermosa</td>\n",
       "      <td>you sure are pretty</td>\n",
       "      <td>i know how eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5776</th>\n",
       "      <td>prueba esta salsa</td>\n",
       "      <td>try this sauce</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>tom se movió</td>\n",
       "      <td>tom moved</td>\n",
       "      <td>tom became a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>ella se vestía como un niño</td>\n",
       "      <td>she dressed like a boy</td>\n",
       "      <td>im am of  this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>tengo que ir al banco</td>\n",
       "      <td>i have to go to the bank</td>\n",
       "      <td>tom thinks mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>ahora estoy jugando al fútbol</td>\n",
       "      <td>im playing football now</td>\n",
       "      <td>tom was in work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>ella no vino a fin de cuentas</td>\n",
       "      <td>she didnt come after all</td>\n",
       "      <td>im not a at a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9958</th>\n",
       "      <td>tomás todavía hace vida de soltero</td>\n",
       "      <td>tom is still a bachelor</td>\n",
       "      <td>i can win this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>ella desvió la vista</td>\n",
       "      <td>she turned her eyes away</td>\n",
       "      <td>im not to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>él es un buen doctor</td>\n",
       "      <td>he is a good doctor</td>\n",
       "      <td>he is a to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>este libro es una novela policíaca</td>\n",
       "      <td>this book is a whodunit</td>\n",
       "      <td>this is  my of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>me puse enfermo</td>\n",
       "      <td>i got sick</td>\n",
       "      <td>we back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>ellos son bienintencionados</td>\n",
       "      <td>they mean well</td>\n",
       "      <td>please they</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ES                     actual  \\\n",
       "7436            no soy la hermana de tom         im not toms sister   \n",
       "3798                  no debes salir hoy  you must not go out today   \n",
       "6781              eres realmente hermosa        you sure are pretty   \n",
       "5776                   prueba esta salsa             try this sauce   \n",
       "7819                        tom se movió                  tom moved   \n",
       "9864         ella se vestía como un niño     she dressed like a boy   \n",
       "5702               tengo que ir al banco   i have to go to the bank   \n",
       "6264       ahora estoy jugando al fútbol    im playing football now   \n",
       "865        ella no vino a fin de cuentas   she didnt come after all   \n",
       "9958  tomás todavía hace vida de soltero    tom is still a bachelor   \n",
       "4682                ella desvió la vista   she turned her eyes away   \n",
       "3450                él es un buen doctor        he is a good doctor   \n",
       "2699  este libro es una novela policíaca    this book is a whodunit   \n",
       "9365                     me puse enfermo                 i got sick   \n",
       "4513         ellos son bienintencionados             they mean well   \n",
       "\n",
       "                      predicted  \n",
       "7436        im not your tom      \n",
       "3798  dont take your choice      \n",
       "6781         i know how eat      \n",
       "5776                that         \n",
       "7819          tom became a       \n",
       "9864          im am of  this     \n",
       "5702       tom thinks mary       \n",
       "6264        tom was in work      \n",
       "865            im not a at a     \n",
       "9958         i can win this      \n",
       "4682             im not to       \n",
       "3450             he is a to      \n",
       "2699          this is  my of     \n",
       "9365              we back        \n",
       "4513          please they        "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  42  30 505   0   0   0   0]\n",
      " [ 68 213   0   0   0   0   0   0]\n",
      " [188   4  51   0   0   0   0   0]]\n",
      "3\n",
      "[[ 11  42  30 505   0   0   0   0]\n",
      " [ 68 213   0   0   0   0   0   0]\n",
      " [188   4  51   0   0   0   0   0]]\n",
      "===========\n",
      "[[   8   15   38   38    0    0    0    0]\n",
      " [  44    5  220    0    0    0    0    0]\n",
      " [ 636   21 2586    0    0    0    0    0]]\n",
      "he was here     \n",
      "youre a mine     \n",
      "save your dice     \n"
     ]
    }
   ],
   "source": [
    "frases=[\"él estaba muy borracho\",\"tienes razón\",\"ve a casa\",]\n",
    "fe=encode_sequences(es_tokenizer, es_length, frases)\n",
    "print(fe)\n",
    "print(\"===========\")\n",
    "pr=model.predict_classes(fe)\n",
    "print(pr)\n",
    "for i in pr:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)           \n",
    "        \n",
    "    print(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## observaciones:\n",
    "'''se han probado dos modelos, el primero, model.h1.4-5-20, mas simple, entrenado con menos palabras y con poco overfitting, que funciona razonablemente bien, es el que se muestra en los resultados anteriores.\n",
    "\n",
    "el segundo, model.h2.5-5-20, se ha entrenado con el doble de palabras y 50 epochs, según el grafico tiene bastante overfitting. Pero cuando observamos los resultados, se puede ver que aunque en muchas situaciones las respuestas no coincida, no se puede decir que sean incorrectas:\n",
    "\n",
    "\n",
    "    español                     Inglés                          Predicción\n",
    "podéis usar ese teléfono\tyou can use that phone         \tyou can use this phone\n",
    "son los mejores\t            you are the best            \tare the best\n",
    "tengo que abrir la ventana\tdo i have to open the window\ti need to open the window\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
